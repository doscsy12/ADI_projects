## Explainable Artificial Intelligence (XAI)

### Introduction
Explainable artificial intelligence (XAI) is a set of tools and methods that allows human users to understand and trust the output and decisions created by AI algorithms. As AI becomes more advanced, it has been challenging to retrace and understand how the algorithms reached its decision, turning AI development into a 'black box' scenario. For example, neural networks used in deep learning are complex and difficult for a human to understand. In addition, bias in the data, often based on gender or age, has been a long-standing risk in training AI models. Thus, XAI will help an organization adopt a responsible approach during AI development, which will build trust and confidence for the users. 

### Aim 
So, the aim of this study is to develop guidelines and a toolkit for data science (DS) teams to demonstrate and conduct responsible AI in an objective and verifiable manner. This will be a unique opportunity to promote transparency between the DS teams and their stakeholders.

#### Guidelines 
The guidelines are meant to be used as a technical reference to integrate XAI methods into DS projects, and provide best practices that will enable explainability to other developers and stakeholders; It is not meant to be a mandatory criterion or compulsory code of practice to be met, in order for projects/teams to be considered XAI-compliant. 

Nonetheless, we believe that XAI can be relevant to ensure that the AI models are making good decisions, even if there is no legal right or regulatory requirements to do so.


|   | file                          | description                    |
|---|-------------------------------|--------------------------------|
|1. |[XAI guidelines ](https://github.com/doscsy12/ADI_projects/blob/main/XAI/XRAI%20Guidelines%20Document%20v2.pdf)  | Guidelines version 2 |

